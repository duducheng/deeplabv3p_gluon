{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiancheng/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "from mxnet import gluon\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# from gluoncv.data import VOCSegmentation, VOCAugSegmentation\n",
    "from gluoncv.utils.metrics.voc_segmentation import batch_pix_accuracy, batch_intersection_union\n",
    "\n",
    "from mylib.deeplabv3p import DeepLabv3p\n",
    "from mylib.dataset import VOCAugSegmentation, COCOSegmentation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "loading annotations into memory...\n",
      "Done (t=11.14s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset = COCOSegmentation(root='/data/dataset/mscoco',split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 480, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 480)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('background',\n",
       " 'airplane',\n",
       " 'bicycle',\n",
       " 'bird',\n",
       " 'boat',\n",
       " 'bottle',\n",
       " 'bus',\n",
       " 'car',\n",
       " 'cat',\n",
       " 'chair',\n",
       " 'cow',\n",
       " 'diningtable',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'motorcycle',\n",
       " 'person',\n",
       " 'potted-plant',\n",
       " 'sheep',\n",
       " 'sofa',\n",
       " 'train',\n",
       " 'tv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = VOCAugSegmentation(split='train_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 512, 512)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = y.copyto(mx.gpu()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.558357"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataloader = gluon.data.DataLoader(dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DeepLabv3p(OS=8)\n",
    "model.initialize(ctx=mx.gpu())\n",
    "# weights = \"/home/jiancheng/code/segmentation/deeplabv3p_gluon/tmp_weights/pascal_trainval/pascal_trainval.params\"\n",
    "weights = '/home/jiancheng/code/segmentation/deeplabv3p_gluon/tmp_weights/pascal_train_aug/pascal_train_aug.params'\n",
    "model.load_params(filename=weights, ctx=mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DeepLabv3p' object has no attribute 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ba7dbbe3d652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DeepLabv3p' object has no attribute 'module'"
     ]
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter181: pix_acc: 0.9387, mIoU: 0.7381: 100%|██████████| 182/182 [04:53<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "tbar = tqdm(dataloader)\n",
    "total_inter, total_union, total_correct, total_label = (0,)*4\n",
    "for i, (x, y) in enumerate(tbar):\n",
    "    x = x.copyto(mx.gpu())\n",
    "    y = y.copyto(mx.gpu())\n",
    "    pred = model(x)\n",
    "    correct, labeled = batch_pix_accuracy(output=pred,target=y)\n",
    "    inter, union = batch_intersection_union(output=pred,target=y,nclass=21)\n",
    "    total_correct += correct.astype('int64')\n",
    "    total_label += labeled.astype('int64')\n",
    "    total_inter += inter.astype('int64')\n",
    "    total_union += union.astype('int64')\n",
    "    pix_acc = np.float64(1.0) * total_correct / (np.spacing(1, dtype=np.float64) + total_label)\n",
    "    IoU = np.float64(1.0) * total_inter / (np.spacing(1, dtype=np.float64) + total_union)\n",
    "    mIoU = IoU.mean()\n",
    "    tbar.set_description('iter%s: pix_acc: %.4f, mIoU: %.4f' % (i, pix_acc, mIoU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DeepLabv3p(OS=16)\n",
    "model.initialize(ctx=mx.gpu())\n",
    "# weights = \"/home/jiancheng/code/segmentation/deeplabv3p_gluon/tmp_weights/pascal_trainval/pascal_trainval.params\"\n",
    "weights = '/home/jiancheng/code/segmentation/deeplabv3p_gluon/tmp_weights/pascal_train_aug/pascal_train_aug.params'\n",
    "model.load_params(filename=weights, ctx=mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter181: pix_acc: 0.9249, mIoU: 0.6991: 100%|██████████| 182/182 [01:29<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "tbar = tqdm(dataloader)\n",
    "total_inter, total_union, total_correct, total_label = (0,)*4\n",
    "for i, (x, y) in enumerate(tbar):\n",
    "    x = x.copyto(mx.gpu())\n",
    "    y = y.copyto(mx.gpu())\n",
    "    pred = model(x)\n",
    "    correct, labeled = batch_pix_accuracy(output=pred,target=y)\n",
    "    inter, union = batch_intersection_union(output=pred,target=y,nclass=21)\n",
    "    total_correct += correct.astype('int64')\n",
    "    total_label += labeled.astype('int64')\n",
    "    total_inter += inter.astype('int64')\n",
    "    total_union += union.astype('int64')\n",
    "    pix_acc = np.float64(1.0) * total_correct / (np.spacing(1, dtype=np.float64) + total_label)\n",
    "    IoU = np.float64(1.0) * total_inter / (np.spacing(1, dtype=np.float64) + total_union)\n",
    "    mIoU = IoU.mean()\n",
    "    tbar.set_description('iter%s: pix_acc: %.4f, mIoU: %.4f' % (i, pix_acc, mIoU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DeepLabv3p(OS=8)\n",
    "model.initialize(ctx=mx.gpu())\n",
    "weights = \"/home/jiancheng/code/segmentation/deeplabv3p_gluon/tmp_weights/pascal_trainval/pascal_trainval.params\"\n",
    "# weights = '/home/jiancheng/code/segmentation/deeplabv3p_gluon/tmp_weights/pascal_train_aug/pascal_train_aug.params'\n",
    "model.load_params(filename=weights, ctx=mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iter181: pix_acc: 0.9667, mIoU: 0.8395: 100%|██████████| 182/182 [04:45<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "tbar = tqdm(dataloader)\n",
    "total_inter, total_union, total_correct, total_label = (0,)*4\n",
    "for i, (x, y) in enumerate(tbar):\n",
    "    x = x.copyto(mx.gpu())\n",
    "    y = y.copyto(mx.gpu())\n",
    "    pred = model(x)\n",
    "    correct, labeled = batch_pix_accuracy(output=pred,target=y)\n",
    "    inter, union = batch_intersection_union(output=pred,target=y,nclass=21)\n",
    "    total_correct += correct.astype('int64')\n",
    "    total_label += labeled.astype('int64')\n",
    "    total_inter += inter.astype('int64')\n",
    "    total_union += union.astype('int64')\n",
    "    pix_acc = np.float64(1.0) * total_correct / (np.spacing(1, dtype=np.float64) + total_label)\n",
    "    IoU = np.float64(1.0) * total_inter / (np.spacing(1, dtype=np.float64) + total_union)\n",
    "    mIoU = IoU.mean()\n",
    "    tbar.set_description('iter%s: pix_acc: %.4f, mIoU: %.4f' % (i, pix_acc, mIoU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83952060808054962"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IoU.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96210574,  0.86299041,  0.60878387,  0.84180434,  0.84475334,\n",
       "        0.65800261,  0.87724081,  0.86911982,  0.91654737,  0.70522442,\n",
       "        0.95383716,  0.83625859,  0.91960927,  0.89853939,  0.8757581 ,\n",
       "        0.91294396,  0.67998638,  0.88289161,  0.75003861,  0.89003154,\n",
       "        0.88346542])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float64(1.0) * total_inter / (np.spacing(1, dtype=np.float64) + total_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83952060808054962"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
